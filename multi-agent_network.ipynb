{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "repl = PythonREPL()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15220\\347796640.py:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_15220\\347796640.py:13: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  code}\\n\\`\\`\\`\\nStdout: {result}\"\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "\n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{\n",
    "        code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return (\n",
    "        result_str + \"\\n\\nIf you have completed all tasks, respond with FINAL ANSWER.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_system_prompt(suffix: str) -> str:\n",
    "    return (\n",
    "        \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
    "        \" Use the provided tools to progress towards answering the question.\"\n",
    "        \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
    "        \" will help where you left off. Execute what you can to make progress.\"\n",
    "        \" If you or any of the other assistants have the final answer or deliverable,\"\n",
    "        \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
    "        f\"\\n{suffix}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_MODEL = os.getenv(\"GROQ_MODEL\")\n",
    "GROQ_API = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = ChatGroq(api_key=GROQ_API, model=GROQ_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_node(last_message: BaseMessage, goto: str):\n",
    "    if \"FINAL ANSWER\" in last_message.content:\n",
    "        return END\n",
    "    return goto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=[tavily_tool],\n",
    "    prompt=make_system_prompt(\n",
    "        \"You can only do research. You are working with a chart generator colleague.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def research_node(state: MessagesState) -> Command[Literal[\"chart_generator\", END]]:\n",
    "    result = research_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"chart_generator\")\n",
    "\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"researcher\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_agent = create_react_agent(\n",
    "    llm,\n",
    "    [python_repl_tool],\n",
    "    prompt=make_system_prompt(\n",
    "        \"You can only generate charts. You are working with a researcher colleague.\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_node(state: MessagesState) -> Command[Literal[\"researcher\", END]]:\n",
    "    result = chart_agent.invoke(state)\n",
    "    goto = get_next_node(result[\"messages\"][-1], \"researcher\")\n",
    "\n",
    "    result[\"messages\"][-1] = HumanMessage(\n",
    "        content=result[\"messages\"][-1].content, name=\"chart_generator\"\n",
    "    )\n",
    "    return Command(\n",
    "        update={\n",
    "\n",
    "            \"messages\": result[\"messages\"],\n",
    "        },\n",
    "        goto=goto,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "workflow.add_node(\"researcher\", research_node)\n",
    "workflow.add_node(\"chart_generator\", chart_node)\n",
    "\n",
    "workflow.add_edge(START, \"researcher\")\n",
    "graph = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool-use>\\n{\\n\\t\"tool_calls\": [\\n\\t\\t{\\n\\t\\t\\t\"id\": \"pending\",\\n\\t\\t\\t\"type\": \"function\",\\n\\t\\t\\t\"function\": {\\n\\t\\t\\t\\t\"name\": \"get_uk_gdp_data\"\\n\\t\\t\\t},\\n\\t\\t\\t\"parameters\": {\\n\\t\\t\\t\\t\"start_year\": \"2017\",\\n\\t\\t\\t\\t\"end_year\": \"2021\"\\n\\t\\t\\t}\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\t\"id\": \"pending\",\\n\\t\\t\\t\"type\": \"function\",\\n\\t\\t\\t\"function\": {\\n\\t\\t\\t\\t\"name\": \"create_line_chart\"\\n\\t\\t\\t},\\n\\t\\t\\t\"parameters\": {\\n\\t\\t\\t\\t\"data\": {\\n\\t\\t\\t\\t\\t\"x_axis\": \"Year\",\\n\\t\\t\\t\\t\\t\"y_axis\": \"GDP (billions GBP)\",\\n\\t\\t\\t\\t\\t\"series\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"name\": \"UK GDP\",\\n\\t\\t\\t\\t\\t\\t\\t\"data\": []\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t]\\n}\\n</tool-use>'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m events \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mstream(\n\u001b[0;32m      2\u001b[0m     {\n\u001b[0;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m: [\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrecursion_limit\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m150\u001b[39m},\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m events:\n\u001b[0;32m     15\u001b[0m     \u001b[39mprint\u001b[39;49m(s)\n\u001b[0;32m     16\u001b[0m     \u001b[39mprint\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m----\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2340\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2334\u001b[0m     \u001b[39m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2335\u001b[0m     \u001b[39m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   2336\u001b[0m     \u001b[39m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m     \u001b[39m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m     \u001b[39m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m     \u001b[39mwhile\u001b[39;00m loop\u001b[39m.\u001b[39mtick(input_keys\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_channels):\n\u001b[1;32m-> 2340\u001b[0m         \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m runner\u001b[39m.\u001b[39;49mtick(\n\u001b[0;32m   2341\u001b[0m             loop\u001b[39m.\u001b[39;49mtasks\u001b[39m.\u001b[39;49mvalues(),\n\u001b[0;32m   2342\u001b[0m             timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_timeout,\n\u001b[0;32m   2343\u001b[0m             retry_policy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretry_policy,\n\u001b[0;32m   2344\u001b[0m             get_waiter\u001b[39m=\u001b[39;49mget_waiter,\n\u001b[0;32m   2345\u001b[0m         ):\n\u001b[0;32m   2346\u001b[0m             \u001b[39m# emit output\u001b[39;49;00m\n\u001b[0;32m   2347\u001b[0m             \u001b[39myield from\u001b[39;49;00m output()\n\u001b[0;32m   2348\u001b[0m \u001b[39m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\pregel\\runner.py:158\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    156\u001b[0m t \u001b[39m=\u001b[39m tasks[\u001b[39m0\u001b[39m]\n\u001b[0;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     run_with_retry(\n\u001b[0;32m    159\u001b[0m         t,\n\u001b[0;32m    160\u001b[0m         retry_policy,\n\u001b[0;32m    161\u001b[0m         configurable\u001b[39m=\u001b[39;49m{\n\u001b[0;32m    162\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[0;32m    163\u001b[0m                 _call,\n\u001b[0;32m    164\u001b[0m                 weakref\u001b[39m.\u001b[39;49mref(t),\n\u001b[0;32m    165\u001b[0m                 retry\u001b[39m=\u001b[39;49mretry_policy,\n\u001b[0;32m    166\u001b[0m                 futures\u001b[39m=\u001b[39;49mweakref\u001b[39m.\u001b[39;49mref(futures),\n\u001b[0;32m    167\u001b[0m                 schedule_task\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mschedule_task,\n\u001b[0;32m    168\u001b[0m                 submit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubmit,\n\u001b[0;32m    169\u001b[0m                 reraise\u001b[39m=\u001b[39;49mreraise,\n\u001b[0;32m    170\u001b[0m             ),\n\u001b[0;32m    171\u001b[0m         },\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommit(t, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    174\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[39m.\u001b[39mwrites\u001b[39m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[39m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m task\u001b[39m.\u001b[39;49mproc\u001b[39m.\u001b[39;49minvoke(task\u001b[39m.\u001b[39;49minput, config)\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m ParentCommand \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:606\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m config \u001b[39m=\u001b[39m patch_config(\n\u001b[0;32m    603\u001b[0m     config, callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseq:step:\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    604\u001b[0m )\n\u001b[0;32m    605\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 606\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    607\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:371\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     \u001b[39mwith\u001b[39;00m set_config_context(config) \u001b[39mas\u001b[39;00m context:\n\u001b[1;32m--> 371\u001b[0m         ret \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    372\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(ret, Runnable) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecurse:\n\u001b[0;32m    373\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m, in \u001b[0;36mresearch_node\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mresearch_node\u001b[39m(state: MessagesState) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Command[Literal[\u001b[39m\"\u001b[39m\u001b[39mchart_generator\u001b[39m\u001b[39m\"\u001b[39m, END]]:\n\u001b[1;32m----> 2\u001b[0m     result \u001b[39m=\u001b[39m research_agent\u001b[39m.\u001b[39;49minvoke(state)\n\u001b[0;32m      3\u001b[0m     goto \u001b[39m=\u001b[39m get_next_node(result[\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mchart_generator\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     result[\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m HumanMessage(\n\u001b[0;32m      6\u001b[0m         content\u001b[39m=\u001b[39mresult[\u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mcontent, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresearcher\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2688\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2686\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2687\u001b[0m     chunks \u001b[39m=\u001b[39m []\n\u001b[1;32m-> 2688\u001b[0m \u001b[39mfor\u001b[39;49;00m chunk \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream(\n\u001b[0;32m   2689\u001b[0m     \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   2690\u001b[0m     config,\n\u001b[0;32m   2691\u001b[0m     stream_mode\u001b[39m=\u001b[39;49mstream_mode,\n\u001b[0;32m   2692\u001b[0m     output_keys\u001b[39m=\u001b[39;49moutput_keys,\n\u001b[0;32m   2693\u001b[0m     interrupt_before\u001b[39m=\u001b[39;49minterrupt_before,\n\u001b[0;32m   2694\u001b[0m     interrupt_after\u001b[39m=\u001b[39;49minterrupt_after,\n\u001b[0;32m   2695\u001b[0m     debug\u001b[39m=\u001b[39;49mdebug,\n\u001b[0;32m   2696\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m   2697\u001b[0m ):\n\u001b[0;32m   2698\u001b[0m     \u001b[39mif\u001b[39;49;00m stream_mode \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mvalues\u001b[39;49m\u001b[39m\"\u001b[39;49m:\n\u001b[0;32m   2699\u001b[0m         latest \u001b[39m=\u001b[39;49m chunk\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2340\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2334\u001b[0m     \u001b[39m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[0;32m   2335\u001b[0m     \u001b[39m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[0;32m   2336\u001b[0m     \u001b[39m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[0;32m   2337\u001b[0m     \u001b[39m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[0;32m   2338\u001b[0m     \u001b[39m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[0;32m   2339\u001b[0m     \u001b[39mwhile\u001b[39;00m loop\u001b[39m.\u001b[39mtick(input_keys\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_channels):\n\u001b[1;32m-> 2340\u001b[0m         \u001b[39mfor\u001b[39;49;00m _ \u001b[39min\u001b[39;49;00m runner\u001b[39m.\u001b[39;49mtick(\n\u001b[0;32m   2341\u001b[0m             loop\u001b[39m.\u001b[39;49mtasks\u001b[39m.\u001b[39;49mvalues(),\n\u001b[0;32m   2342\u001b[0m             timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_timeout,\n\u001b[0;32m   2343\u001b[0m             retry_policy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretry_policy,\n\u001b[0;32m   2344\u001b[0m             get_waiter\u001b[39m=\u001b[39;49mget_waiter,\n\u001b[0;32m   2345\u001b[0m         ):\n\u001b[0;32m   2346\u001b[0m             \u001b[39m# emit output\u001b[39;49;00m\n\u001b[0;32m   2347\u001b[0m             \u001b[39myield from\u001b[39;49;00m output()\n\u001b[0;32m   2348\u001b[0m \u001b[39m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\pregel\\runner.py:158\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[0;32m    156\u001b[0m t \u001b[39m=\u001b[39m tasks[\u001b[39m0\u001b[39m]\n\u001b[0;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     run_with_retry(\n\u001b[0;32m    159\u001b[0m         t,\n\u001b[0;32m    160\u001b[0m         retry_policy,\n\u001b[0;32m    161\u001b[0m         configurable\u001b[39m=\u001b[39;49m{\n\u001b[0;32m    162\u001b[0m             CONFIG_KEY_CALL: partial(\n\u001b[0;32m    163\u001b[0m                 _call,\n\u001b[0;32m    164\u001b[0m                 weakref\u001b[39m.\u001b[39;49mref(t),\n\u001b[0;32m    165\u001b[0m                 retry\u001b[39m=\u001b[39;49mretry_policy,\n\u001b[0;32m    166\u001b[0m                 futures\u001b[39m=\u001b[39;49mweakref\u001b[39m.\u001b[39;49mref(futures),\n\u001b[0;32m    167\u001b[0m                 schedule_task\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mschedule_task,\n\u001b[0;32m    168\u001b[0m                 submit\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubmit,\n\u001b[0;32m    169\u001b[0m                 reraise\u001b[39m=\u001b[39;49mreraise,\n\u001b[0;32m    170\u001b[0m             ),\n\u001b[0;32m    171\u001b[0m         },\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommit(t, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    174\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[39m.\u001b[39mwrites\u001b[39m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[39m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[39mreturn\u001b[39;00m task\u001b[39m.\u001b[39;49mproc\u001b[39m.\u001b[39;49minvoke(task\u001b[39m.\u001b[39;49minput, config)\n\u001b[0;32m     41\u001b[0m \u001b[39mexcept\u001b[39;00m ParentCommand \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:606\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m config \u001b[39m=\u001b[39m patch_config(\n\u001b[0;32m    603\u001b[0m     config, callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mseq:step:\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    604\u001b[0m )\n\u001b[0;32m    605\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 606\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39;49minvoke(\u001b[39minput\u001b[39;49m, config, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    607\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    608\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m step\u001b[39m.\u001b[39minvoke(\u001b[39minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\utils\\runnable.py:363\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m     child_config \u001b[39m=\u001b[39m patch_config(config, callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child())\n\u001b[0;32m    362\u001b[0m     \u001b[39mwith\u001b[39;00m set_config_context(child_config) \u001b[39mas\u001b[39;00m context:\n\u001b[1;32m--> 363\u001b[0m         ret \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    364\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    365\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langgraph\\prebuilt\\chat_agent_executor.py:745\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[1;34m(state, config)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_model\u001b[39m(state: StateSchema, config: RunnableConfig) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m StateSchema:\n\u001b[0;32m    744\u001b[0m     state \u001b[39m=\u001b[39m _get_model_input_state(state)\n\u001b[1;32m--> 745\u001b[0m     response \u001b[39m=\u001b[39m cast(AIMessage, model_runnable\u001b[39m.\u001b[39;49minvoke(state, config))\n\u001b[0;32m    746\u001b[0m     \u001b[39m# add agent name to the AIMessage\u001b[39;00m\n\u001b[0;32m    747\u001b[0m     response\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m name\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3034\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3032\u001b[0m                 \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39mrun(step\u001b[39m.\u001b[39minvoke, \u001b[39minput\u001b[39m, config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   3033\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 3034\u001b[0m                 \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39;49mrun(step\u001b[39m.\u001b[39;49minvoke, \u001b[39minput\u001b[39;49m, config)\n\u001b[0;32m   3035\u001b[0m \u001b[39m# finish the root run\u001b[39;00m\n\u001b[0;32m   3036\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5409\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[0;32m   5410\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[0;32m   5411\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5414\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5415\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Output:\n\u001b[1;32m-> 5416\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound\u001b[39m.\u001b[39;49minvoke(\n\u001b[0;32m   5417\u001b[0m         \u001b[39minput\u001b[39;49m,\n\u001b[0;32m   5418\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_merge_configs(config),\n\u001b[0;32m   5419\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m{\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs},\n\u001b[0;32m   5420\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:369\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[0;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvoke\u001b[39m(\n\u001b[0;32m    359\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    365\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[0;32m    366\u001b[0m     config \u001b[39m=\u001b[39m ensure_config(config)\n\u001b[0;32m    367\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(\n\u001b[0;32m    368\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mChatGeneration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m--> 369\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_prompt(\n\u001b[0;32m    370\u001b[0m             [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_input(\u001b[39minput\u001b[39;49m)],\n\u001b[0;32m    371\u001b[0m             stop\u001b[39m=\u001b[39;49mstop,\n\u001b[0;32m    372\u001b[0m             callbacks\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallbacks\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    373\u001b[0m             tags\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mtags\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    374\u001b[0m             metadata\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    375\u001b[0m             run_name\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mrun_name\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    376\u001b[0m             run_id\u001b[39m=\u001b[39;49mconfig\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mrun_id\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    377\u001b[0m             \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    378\u001b[0m         )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m],\n\u001b[0;32m    379\u001b[0m     )\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:946\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    937\u001b[0m \u001b[39m@override\u001b[39m\n\u001b[0;32m    938\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(\n\u001b[0;32m    939\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    943\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    944\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m LLMResult:\n\u001b[0;32m    945\u001b[0m     prompt_messages \u001b[39m=\u001b[39m [p\u001b[39m.\u001b[39mto_messages() \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m prompts]\n\u001b[1;32m--> 946\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate(prompt_messages, stop\u001b[39m=\u001b[39;49mstop, callbacks\u001b[39m=\u001b[39;49mcallbacks, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:765\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[39mfor\u001b[39;00m i, m \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(input_messages):\n\u001b[0;32m    763\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m         results\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> 765\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate_with_cache(\n\u001b[0;32m    766\u001b[0m                 m,\n\u001b[0;32m    767\u001b[0m                 stop\u001b[39m=\u001b[39;49mstop,\n\u001b[0;32m    768\u001b[0m                 run_manager\u001b[39m=\u001b[39;49mrun_managers[i] \u001b[39mif\u001b[39;49;00m run_managers \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    769\u001b[0m                 \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    770\u001b[0m             )\n\u001b[0;32m    771\u001b[0m         )\n\u001b[0;32m    772\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    773\u001b[0m         \u001b[39mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1011\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     result \u001b[39m=\u001b[39m generate_from_stream(\u001b[39miter\u001b[39m(chunks))\n\u001b[0;32m   1010\u001b[0m \u001b[39melif\u001b[39;00m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1011\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[0;32m   1012\u001b[0m         messages, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m   1013\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1015\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(messages, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\langchain_groq\\chat_models.py:503\u001b[0m, in \u001b[0;36mChatGroq._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    498\u001b[0m message_dicts, params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[0;32m    499\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[0;32m    500\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    501\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    502\u001b[0m }\n\u001b[1;32m--> 503\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(messages\u001b[39m=\u001b[39;49mmessage_dicts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[0;32m    504\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:298\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    158\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    159\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    186\u001b[0m     timeout: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m httpx\u001b[39m.\u001b[39mTimeout \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m NotGiven \u001b[39m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    187\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ChatCompletion \u001b[39m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m    188\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_post(\n\u001b[0;32m    299\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m/openai/v1/chat/completions\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    300\u001b[0m         body\u001b[39m=\u001b[39;49mmaybe_transform(\n\u001b[0;32m    301\u001b[0m             {\n\u001b[0;32m    302\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m: messages,\n\u001b[0;32m    303\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m: model,\n\u001b[0;32m    304\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfrequency_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: frequency_penalty,\n\u001b[0;32m    305\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunction_call\u001b[39;49m\u001b[39m\"\u001b[39;49m: function_call,\n\u001b[0;32m    306\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: functions,\n\u001b[0;32m    307\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogit_bias\u001b[39;49m\u001b[39m\"\u001b[39;49m: logit_bias,\n\u001b[0;32m    308\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mlogprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: logprobs,\n\u001b[0;32m    309\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mmax_tokens\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_tokens,\n\u001b[0;32m    310\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m: n,\n\u001b[0;32m    311\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mparallel_tool_calls\u001b[39;49m\u001b[39m\"\u001b[39;49m: parallel_tool_calls,\n\u001b[0;32m    312\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mpresence_penalty\u001b[39;49m\u001b[39m\"\u001b[39;49m: presence_penalty,\n\u001b[0;32m    313\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mresponse_format\u001b[39;49m\u001b[39m\"\u001b[39;49m: response_format,\n\u001b[0;32m    314\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mseed\u001b[39;49m\u001b[39m\"\u001b[39;49m: seed,\n\u001b[0;32m    315\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstop\u001b[39;49m\u001b[39m\"\u001b[39;49m: stop,\n\u001b[0;32m    316\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mstream\u001b[39;49m\u001b[39m\"\u001b[39;49m: stream,\n\u001b[0;32m    317\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: temperature,\n\u001b[0;32m    318\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtool_choice\u001b[39;49m\u001b[39m\"\u001b[39;49m: tool_choice,\n\u001b[0;32m    319\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtools\u001b[39;49m\u001b[39m\"\u001b[39;49m: tools,\n\u001b[0;32m    320\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_logprobs\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_logprobs,\n\u001b[0;32m    321\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mtop_p\u001b[39;49m\u001b[39m\"\u001b[39;49m: top_p,\n\u001b[0;32m    322\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m: user,\n\u001b[0;32m    323\u001b[0m             },\n\u001b[0;32m    324\u001b[0m             completion_create_params\u001b[39m.\u001b[39;49mCompletionCreateParams,\n\u001b[0;32m    325\u001b[0m         ),\n\u001b[0;32m    326\u001b[0m         options\u001b[39m=\u001b[39;49mmake_request_options(\n\u001b[0;32m    327\u001b[0m             extra_headers\u001b[39m=\u001b[39;49mextra_headers, extra_query\u001b[39m=\u001b[39;49mextra_query, extra_body\u001b[39m=\u001b[39;49mextra_body, timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[0;32m    328\u001b[0m         ),\n\u001b[0;32m    329\u001b[0m         cast_to\u001b[39m=\u001b[39;49mChatCompletion,\n\u001b[0;32m    330\u001b[0m         stream\u001b[39m=\u001b[39;49mstream \u001b[39mor\u001b[39;49;00m \u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    331\u001b[0m         stream_cls\u001b[39m=\u001b[39;49mStream[ChatCompletionChunk],\n\u001b[0;32m    332\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\groq\\_base_client.py:1263\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpost\u001b[39m(\n\u001b[0;32m   1250\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1251\u001b[0m     path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1258\u001b[0m     stream_cls: \u001b[39mtype\u001b[39m[_StreamT] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   1259\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ResponseT \u001b[39m|\u001b[39m _StreamT:\n\u001b[0;32m   1260\u001b[0m     opts \u001b[39m=\u001b[39m FinalRequestOptions\u001b[39m.\u001b[39mconstruct(\n\u001b[0;32m   1261\u001b[0m         method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpost\u001b[39m\u001b[39m\"\u001b[39m, url\u001b[39m=\u001b[39mpath, json_data\u001b[39m=\u001b[39mbody, files\u001b[39m=\u001b[39mto_httpx_files(files), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions\n\u001b[0;32m   1262\u001b[0m     )\n\u001b[1;32m-> 1263\u001b[0m     \u001b[39mreturn\u001b[39;00m cast(ResponseT, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(cast_to, opts, stream\u001b[39m=\u001b[39;49mstream, stream_cls\u001b[39m=\u001b[39;49mstream_cls))\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\groq\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\n\u001b[0;32m    956\u001b[0m     cast_to\u001b[39m=\u001b[39;49mcast_to,\n\u001b[0;32m    957\u001b[0m     options\u001b[39m=\u001b[39;49moptions,\n\u001b[0;32m    958\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    959\u001b[0m     stream_cls\u001b[39m=\u001b[39;49mstream_cls,\n\u001b[0;32m    960\u001b[0m     retries_taken\u001b[39m=\u001b[39;49mretries_taken,\n\u001b[0;32m    961\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\groq\\_base_client.py:1058\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         err\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mread()\n\u001b[0;32m   1057\u001b[0m     log\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRe-raising status error\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1058\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_status_error_from_response(err\u001b[39m.\u001b[39mresponse) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1060\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_response(\n\u001b[0;32m   1061\u001b[0m     cast_to\u001b[39m=\u001b[39mcast_to,\n\u001b[0;32m   1062\u001b[0m     options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     retries_taken\u001b[39m=\u001b[39mretries_taken,\n\u001b[0;32m   1067\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool-use>\\n{\\n\\t\"tool_calls\": [\\n\\t\\t{\\n\\t\\t\\t\"id\": \"pending\",\\n\\t\\t\\t\"type\": \"function\",\\n\\t\\t\\t\"function\": {\\n\\t\\t\\t\\t\"name\": \"get_uk_gdp_data\"\\n\\t\\t\\t},\\n\\t\\t\\t\"parameters\": {\\n\\t\\t\\t\\t\"start_year\": \"2017\",\\n\\t\\t\\t\\t\"end_year\": \"2021\"\\n\\t\\t\\t}\\n\\t\\t},\\n\\t\\t{\\n\\t\\t\\t\"id\": \"pending\",\\n\\t\\t\\t\"type\": \"function\",\\n\\t\\t\\t\"function\": {\\n\\t\\t\\t\\t\"name\": \"create_line_chart\"\\n\\t\\t\\t},\\n\\t\\t\\t\"parameters\": {\\n\\t\\t\\t\\t\"data\": {\\n\\t\\t\\t\\t\\t\"x_axis\": \"Year\",\\n\\t\\t\\t\\t\\t\"y_axis\": \"GDP (billions GBP)\",\\n\\t\\t\\t\\t\\t\"series\": [\\n\\t\\t\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\t\\t\\t\"name\": \"UK GDP\",\\n\\t\\t\\t\\t\\t\\t\\t\"data\": []\\n\\t\\t\\t\\t\\t\\t}\\n\\t\\t\\t\\t\\t]\\n\\t\\t\\t\\t}\\n\\t\\t\\t}\\n\\t\\t}\\n\\t]\\n}\\n</tool-use>'}}",
      "\u001b[0mDuring task with name 'agent' and id '21a9318b-06ca-4998-373c-57f056675ec6'",
      "\u001b[0mDuring task with name 'researcher' and id '2756f665-8890-feea-4580-30f9f4dbd3c0'"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"First, get the UK's GDP over the past 5 years, then make a line chart of it. \"\n",
    "                \"Once you make the chart, finish.\",\n",
    "            )\n",
    "        ],\n",
    "    },\n",
    "\n",
    "    {\"recursion_limit\": 150},\n",
    ")\n",
    "for s in events:\n",
    "    print(s)\n",
    "    print(\"----\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
